---
abstract: A patient’s clinical notes correspond to a sequence of free-form text documents
  generated by healthcare professionals over time. Rich and unique information in
  clinical notes is useful for clinical decision making. In this work, we propose
  a time-aware transformer-based hierarchical architecture, which we call Flexible
  Time-aware LSTM Transformer (FTL-Trans), for classifying a patient’s health state
  based on her series of clinical notes. FTL-Trans addresses the problem that current
  transformer-based architectures cannot handle, which is the multi-level structure
  inherent in clinical note series where a note contains a sequence of chucks and
  a chuck contains further a sequence of words. At the bottom layer, FTL-Trans encodes
  equal-length subsequences of a patient’s clinical notes ("chunks") into content
  embeddings using a pre-trained ClinicalBERT model. Unlike ClinicalBERT, however,
  FTL-Trans merges each content embedding and sequential information into a new position-enhanced
  chunk representation in the second layer by an augmented multi-level position embedding.
  Next, the time-aware layer tackles the irregularity in the spacing of notes in the
  note series by learning a flexible time decay function and utilizing the time decay
  function to incorporate both the position-enhanced chunk embedding and time information
  into a patient representation. This patient representation is then fed into the
  top layer for classification. Together, this hierarchical design of FTL-Trans successfully
  captures the multi-level sequential structure of the note series. Our extensive
  experimental evaluation conducted using multiple patient cohorts extracted from
  the MIMIC dataset illustrates that, while addressing the aforementioned issues,
  FTL-Trans consistently outperforms the state-of-the-art transformer-based architectures
  up to 5% in AUROC and 6% in Accuracy.
booktitle: Proceedings of the 5th Machine Learning for Healthcare Conference
title: Time-Aware Transformer-based Network for Clinical Notes Series Prediction
volume: '126'
year: '2020'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang20c
month: 0
tex_title: Time-Aware Transformer-based Network for Clinical Notes Series Prediction
firstpage: 566
lastpage: 588
page: 566-588
order: 566
cycles: false
bibtex_author: Zhang, Dongyu and Thadajarassiri, Jidapa and Sen, Cansu and Rundensteiner,
  Elke
author:
- given: Dongyu
  family: Zhang
- given: Jidapa
  family: Thadajarassiri
- given: Cansu
  family: Sen
- given: Elke
  family: Rundensteiner
date: 2020-09-18
address: 
container-title: Proceedings of the 5th Machine Learning for Healthcare Conference
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 18
pdf: http://proceedings.mlr.press/v126/zhang20c/zhang20c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
