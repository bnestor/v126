---
abstract: It is often infeasible or impossible to obtain ground truth labels for medical
  data. To circumvent this, one may build rule-based or other expert-knowledge driven
  labelers to ingest data and yield silver labels absent any ground-truth training
  data. One popular such labeler is CheXpert (Irvin et al., 2019), a labeler that
  produces diagnostic labels for chest X-ray radiology reports. CheXpert is very useful,
  but is relatively computationally slow, especially when integrated with end-to-end
  neural pipelines, is non-differentiable so canâ€™t be used in any applications that
  require gradients to flow through the labeler, and does not yield probabilistic
  outputs, which limits our ability to improve the quality of the silver labeler through
  techniques such as active learning. In this work, we solve all three of these problems
  with CheXpert++, a BERT-based, high-fidelity approximation to CheXpert. CheXpert++
  achieves 99.81% parity with CheXpert, which means it can be reliably used as a drop-in
  replacement for CheXpert, all while being significantly faster, fully differentiable,
  and probabilistic in output. Error analysis of CheXpert++ also demonstrates that
  CheXpert++ has a tendency to actually correct errors in the CheXpert labels, with
  CheXpert++ labels being more often preferred by a clinician over CheXpert labels
  (when they disagree) on all but one disease task. To further demonstrate the utility
  of these advantages in this model, we conduct a proof-of-concept active learning
  study, demonstrating we can improve accuracy on an expert labeled random subset
  of report sentences by approximately 8% over raw, unaltered CheXpert by using one-iteration
  of active-learning inspired re-training. These findings suggest that simple techniques
  in co-learning and active learning can yield high-quality labelers under minimal,
  and controllable human labeling demands.
booktitle: Proceedings of the 5th Machine Learning for Healthcare Conference
title: 'CheXpert++: Approximating the CheXpert Labeler for Speed, Differentiability,
  and Probabilistic Output'
volume: '126'
year: '2020'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mcdermott20a
month: 0
tex_title: 'CheXpert++: Approximating the CheXpert Labeler for Speed, Differentiability,
  and Probabilistic Output'
firstpage: 913
lastpage: 927
page: 913-927
order: 913
cycles: false
bibtex_author: McDermott, Matthew B.A. and Hsu, Tzu Ming Harry and Weng, Wei-Hung
  and Ghassemi, Marzyeh and Szolovits, Peter
author:
- given: Matthew B.A.
  family: McDermott
- given: Tzu Ming Harry
  family: Hsu
- given: Wei-Hung
  family: Weng
- given: Marzyeh
  family: Ghassemi
- given: Peter
  family: Szolovits
date: 2020-09-18
address: 
container-title: Proceedings of the 5th Machine Learning for Healthcare Conference
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 18
pdf: http://proceedings.mlr.press/v126/mcdermott20a/mcdermott20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
